#version: '3.9'


services:
  cloudflaretunnel:
    env_file: tunnel.env
    container_name: cloudflaretunnel
    image: cloudflare/cloudflared:2023.2.1
    restart: unless-stopped
    command: tunnel --no-autoupdate run
  foundry:
    container_name: foundry
    image: node:19-bullseye
    user: node
    restart: "unless-stopped"
    ports:
      - "30000:30000"
    volumes:
      - ./FoundryVTT:/FoundryVTT
      - ./data:/data
    command: node FoundryVTT/resources/app/main.js --dataPath=/data
  duplicati:
    env_file: duplicati.env
    image: lscr.io/linuxserver/duplicati:latest
    container_name: duplicati
    environment:
      - PUID=1000
      - PGID=1000
      - TZ=Etc/UTC
      - CLI_ARGS= #optional
    volumes:
      - ./duplicaticonfig:/config
      - ./backups:/backups
      - ./data:/source
    ports:
      - 30001:8200
    restart: unless-stopped
  faster-whisper:
   # image: lscr.io/linuxserver/faster-whisper:latest
    image: fitriwibowo/wyoming-whisper:2.2.0
    container_name: faster-whisper
    working_dir: /data/scripts
    environment:
      - PUID=1000
      - PGID=1000
      - TZ=Etc/UTC
      - SESHNAME=Session_1
      - MODEL=distil-large-v3
      - COMPUTETYPE=float32
      - DEVICE=cuda
   # entrypoint: ['bash', '-c', ' ./transcribe.sh -a $$SESHNAME -b $$MODEL -c $$COMPUTETYPE -d $$DEVICE']
    entrypoint: ['bash', '-c']
    command: ['ls -laR /data/ && chmod +x /data/scripts/transcribe.sh && /data/scripts/transcribe.sh -a $$SESHNAME -b $$MODEL -c $$COMPUTETYPE -d $$DEVICE']
  #  command: 'ls -laR /data/ && chmod +x /data/scripts/transcribe.sh && /data/scripts/transcribe.sh -a $$SESHNAME -b $$MODEL -c $$COMPUTETYPE -d $$DEVICE'
   # command: 
    deploy:
      resources:
         reservations:
           devices:
            - driver: nvidia # allows for newer gpu's to use Tenser cores for more speed and power, you have to enable the commented out line in the py code.
              count: 1
              capabilities: [gpu]
           # - cpus: "2.0"  # Reserve at least 2 CPU cores for this container
           # - memory: 4G   # Reserve at least 4GB of memory
         limits:
          cpus: "3.0"  # Limit container to 4 CPU cores
          memory: 16G   # Limit memory usage to 8GB
      #  mem_reservation: 4G  # Memory reservation (for example, 4GB)
      # to use the script for creating transcripts use:  apt update && apt -y install ffmpeg
      # to get into the container use  docker exec -it faster-whisper /bin/bash
    volumes:
      - ./audio:/data/audio  # Audio input files
      - ./transcripts:/data/transcripts  # Transcription outputs
      - ./scripts:/data/scripts  # Python scripts
      - ./config_whisper:/config  # Container-specific persistent files (if needed)
  #  ports:
    #  - 10300:10300
   # restart: unless-stopped

